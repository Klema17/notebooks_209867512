{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e41b79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-{torchversion}.html\n",
    "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-{torchversion}.html\n",
    "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "!pip install torch-geometric pandas numpy scikit-learn networkx matplotlib seaborn tqdm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f014812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psutil\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import average_precision_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATv2Conv, GCNConv, SAGEConv\n",
    "from torch_geometric.utils import to_undirected\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "try:\n",
    "    import pynvml\n",
    "    pynvml.nvmlInit()\n",
    "    NVML_AVAILABLE = True\n",
    "except:\n",
    "    NVML_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1015290f",
   "metadata": {},
   "source": [
    "Загружаем датасет German Credit.\n",
    "Содержит 1000 клиентов и 20 признаков (7 числовых и 13 категориальных)\n",
    "Целевая переменная: \"good\" (1) или \"bad\" (2) кредитная история."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dceef23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружено 1000 узлов, 48 признаков\n",
      "Train/Val/Test: 600/200/200\n",
      "Рёбер: 7528\n",
      "Распределение классов: Класс 0: 700, Класс 1: 300\n"
     ]
    }
   ],
   "source": [
    "german_credit = fetch_ucirepo(id=144)\n",
    "\n",
    "X = german_credit.data.features\n",
    "y = german_credit.data.targets \n",
    "\n",
    "# Заменяем \"good\" на 0, \"bad\" на 1\n",
    "y = y['class'].values\n",
    "y = np.where(y == 1, 0, 1)\n",
    "\n",
    "# Обработка категориальных признаков. pd.get_dummies автоматически кодирует все категориальных колонки. drop_first=True убирает избыточность.\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Стандартизация числовых признаков\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Строим граф методом k-ближайших соседей. Создаётся разреженная матрица смежности с помощью knn. Рёбра только 0/1, петли исключаются. Граф неориентированный.\n",
    "k = 5\n",
    "adj_matrix = kneighbors_graph(X_scaled, k, mode='connectivity', include_self=False)\n",
    "edge_index = torch.tensor(np.array(adj_matrix.nonzero()), dtype=torch.long)\n",
    "edge_index = to_undirected(edge_index)\n",
    "\n",
    "# train / val / test (60/20/20)\n",
    "num_nodes = X_scaled.shape[0]\n",
    "indices = np.arange(num_nodes)\n",
    "\n",
    "train_idx, temp_idx = train_test_split(indices, test_size=0.4, random_state=42)\n",
    "val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=42)\n",
    "\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "train_mask[train_idx] = True\n",
    "val_mask[val_idx] = True\n",
    "test_mask[test_idx] = True\n",
    "\n",
    "data = Data(\n",
    "    x=torch.tensor(X_scaled, dtype=torch.float),\n",
    "    edge_index=edge_index,\n",
    "    y=torch.tensor(y, dtype=torch.long),\n",
    "    train_mask=train_mask,\n",
    "    val_mask=val_mask,\n",
    "    test_mask=test_mask\n",
    ")\n",
    "\n",
    "print(f\"Загружено {data.x.shape[0]} узлов, {data.x.shape[1]} признаков\")\n",
    "print(f\"Train/Val/Test: {train_mask.sum().item()}/{val_mask.sum().item()}/{test_mask.sum().item()}\")\n",
    "print(f\"Рёбер: {edge_index.shape[1]}\")\n",
    "\n",
    "class_counts = torch.bincount(data.y).tolist()\n",
    "class_dist_str = \", \".join(f\"Класс {i}: {count}\" for i, count in enumerate(class_counts))\n",
    "print(f\"Распределение классов: {class_dist_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a48934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычисление весов перед обучением\n",
    "y_train = data.y[data.train_mask].cpu().numpy()\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(data.x.device)\n",
    "\n",
    "# Использование в лоссе\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4174ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred, true, probs=None):\n",
    "    pred = pred.cpu().numpy()\n",
    "    true = true.cpu().numpy()\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': (pred == true).mean(),\n",
    "        'precision': precision_score(true, pred, zero_division=0),\n",
    "        'recall': recall_score(true, pred, zero_division=0),\n",
    "        'f1': f1_score(true, pred, zero_division=0),\n",
    "    }\n",
    "    \n",
    "    if probs is not None:\n",
    "        probs = probs.cpu().numpy()\n",
    "        metrics['roc_auc'] = roc_auc_score(true, probs)\n",
    "        metrics['pr_auc'] = average_precision_score(true, probs)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def accuracy(pred_y, y):\n",
    "    return ((pred_y == y).sum() / len(y)).item()\n",
    "\n",
    "def test(model, data):\n",
    "    \"\"\"Тестирование с полным набором метрик\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        _, out = model(data.x, data.edge_index)\n",
    "        pred = out.argmax(dim=1)[data.test_mask]\n",
    "        probs = torch.exp(out)[:, 1][data.test_mask]  # Вероятность класса 1 (дефолт)\n",
    "        true = data.y[data.test_mask]\n",
    "        \n",
    "        return compute_metrics(pred, true, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83cea4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, dim_in, dim_h, dim_out):\n",
    "        super().__init__()\n",
    "        self.sage1 = SAGEConv(dim_in, dim_h)\n",
    "        self.sage2 = SAGEConv(dim_h, dim_out)\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(),\n",
    "                                        lr=0.01,\n",
    "                                        weight_decay=5e-4)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.sage1(x, edge_index)\n",
    "        h = torch.relu(h)\n",
    "        h = F.dropout(h, p=0.5, training=self.training)\n",
    "        h = self.sage2(h, edge_index)\n",
    "        return h, F.log_softmax(h, dim=1)\n",
    "\n",
    "    def fit(self, data, epochs):\n",
    "        # Взвешенный лосс\n",
    "        y_train = data.y[data.train_mask].cpu().numpy()\n",
    "        weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "        weights = torch.tensor(weights, dtype=torch.float).to(data.x.device)\n",
    "        criterion = torch.nn.CrossEntropyLoss(weight=weights)\n",
    "        optimizer = self.optimizer\n",
    "\n",
    "        self.train()\n",
    "        for epoch in range(epochs + 1):\n",
    "            optimizer.zero_grad()\n",
    "            _, out = self(data.x, data.edge_index)\n",
    "            loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                train_pred = out[data.train_mask].argmax(dim=1)\n",
    "                train_metrics = compute_metrics(train_pred, data.y[data.train_mask])\n",
    "                \n",
    "                val_pred = out[data.val_mask].argmax(dim=1)\n",
    "                val_probs = torch.exp(out)[:, 1][data.val_mask]\n",
    "                val_metrics = compute_metrics(val_pred, data.y[data.val_mask], probs=val_probs)\n",
    "                val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                print(f'Epoch {epoch:>3} | '\n",
    "                    f'TL: {loss:.3f} | TF1: {train_metrics[\"f1\"]:.3f} | '\n",
    "                    f'VL: {val_loss:.3f} | VF1: {val_metrics[\"f1\"]:.3f} | '\n",
    "                    f'VRec: {val_metrics[\"recall\"]:.3f} | VPR: {val_metrics[\"pr_auc\"]:.3f}')\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, dim_in, dim_h, dim_out, heads=4):\n",
    "        super().__init__()\n",
    "        self.gat1 = GATv2Conv(dim_in, dim_h, heads=heads, concat=True, dropout=0.6)\n",
    "        self.gat2 = GATv2Conv(dim_h * heads, dim_out, heads=heads, concat=False, dropout=0.6)\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(),\n",
    "                                        lr=0.005,\n",
    "                                        weight_decay=5e-4)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = F.dropout(x, p=0.6, training=self.training)\n",
    "        h = self.gat1(h, edge_index)\n",
    "        h = F.elu(h)\n",
    "        h = F.dropout(h, p=0.6, training=self.training)\n",
    "        h = self.gat2(h, edge_index)\n",
    "        return h, F.log_softmax(h, dim=1)\n",
    "\n",
    "    def fit(self, data, epochs):\n",
    "        # Взвешенный лосс\n",
    "        y_train = data.y[data.train_mask].cpu().numpy()\n",
    "        weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "        weights = torch.tensor(weights, dtype=torch.float).to(data.x.device)\n",
    "        criterion = torch.nn.CrossEntropyLoss(weight=weights)\n",
    "        optimizer = self.optimizer\n",
    "\n",
    "        self.train()\n",
    "        for epoch in range(epochs + 1):\n",
    "            optimizer.zero_grad()\n",
    "            _, out = self(data.x, data.edge_index)\n",
    "            loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                train_pred = out[data.train_mask].argmax(dim=1)\n",
    "                train_metrics = compute_metrics(train_pred, data.y[data.train_mask])\n",
    "                \n",
    "                val_pred = out[data.val_mask].argmax(dim=1)\n",
    "                val_probs = torch.exp(out)[:, 1][data.val_mask]\n",
    "                val_metrics = compute_metrics(val_pred, data.y[data.val_mask], probs=val_probs)\n",
    "                val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                print(f'Epoch {epoch:>3} | '\n",
    "                    f'TL: {loss:.3f} | TF1: {train_metrics[\"f1\"]:.3f} | '\n",
    "                    f'VL: {val_loss:.3f} | VF1: {val_metrics[\"f1\"]:.3f} | '\n",
    "                    f'VRec: {val_metrics[\"recall\"]:.3f} | VPR: {val_metrics[\"pr_auc\"]:.3f}')\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, dim_in, dim_h, dim_out):\n",
    "        super().__init__()\n",
    "        self.gcn1 = GCNConv(dim_in, dim_h)\n",
    "        self.gcn2 = GCNConv(dim_h, dim_out)\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(),\n",
    "                                        lr=0.01,\n",
    "                                        weight_decay=5e-4)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = F.dropout(x, p=0.5, training=self.training)\n",
    "        h = self.gcn1(h, edge_index)\n",
    "        h = torch.relu(h)\n",
    "        h = F.dropout(h, p=0.5, training=self.training)\n",
    "        h = self.gcn2(h, edge_index)\n",
    "        return h, F.log_softmax(h, dim=1)\n",
    "\n",
    "    def fit(self, data, epochs):\n",
    "        # Взвешенный лосс\n",
    "        y_train = data.y[data.train_mask].cpu().numpy()\n",
    "        weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "        weights = torch.tensor(weights, dtype=torch.float).to(data.x.device)\n",
    "        criterion = torch.nn.CrossEntropyLoss(weight=weights)\n",
    "        optimizer = self.optimizer\n",
    "\n",
    "        self.train()\n",
    "        for epoch in range(epochs + 1):\n",
    "            optimizer.zero_grad()\n",
    "            _, out = self(data.x, data.edge_index)\n",
    "            loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                train_pred = out[data.train_mask].argmax(dim=1)\n",
    "                train_metrics = compute_metrics(train_pred, data.y[data.train_mask])\n",
    "                \n",
    "                val_pred = out[data.val_mask].argmax(dim=1)\n",
    "                val_probs = torch.exp(out)[:, 1][data.val_mask]\n",
    "                val_metrics = compute_metrics(val_pred, data.y[data.val_mask], probs=val_probs)\n",
    "                val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                print(f'Epoch {epoch:>3} | '\n",
    "                    f'TL: {loss:.3f} | TF1: {train_metrics[\"f1\"]:.3f} | '\n",
    "                    f'VL: {val_loss:.3f} | VF1: {val_metrics[\"f1\"]:.3f} | '\n",
    "                    f'VRec: {val_metrics[\"recall\"]:.3f} | VPR: {val_metrics[\"pr_auc\"]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f8006aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = data.to(device)\n",
    "\n",
    "def monitor_resources():\n",
    "    stats = {}\n",
    "    # CPU & RAM\n",
    "    stats['ram_mb'] = psutil.virtual_memory().used / (1024 ** 2)\n",
    "    stats['cpu_percent'] = psutil.cpu_percent()\n",
    "\n",
    "    # GPU\n",
    "    if device.type == 'cuda' and NVML_AVAILABLE:\n",
    "        handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "        mem_info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "        util = pynvml.nvmlDeviceGetUtilizationRates(handle)\n",
    "        stats['gpu_mem_mb'] = mem_info.used / (1024 ** 2)\n",
    "        stats['gpu_util'] = util.gpu\n",
    "    else:\n",
    "        stats['gpu_mem_mb'] = None\n",
    "        stats['gpu_util'] = None\n",
    "    return stats\n",
    "\n",
    "def train_with_monitoring(model, data, epochs, model_name):\n",
    "    print(f\"\\n{'='*50}\\nTraining {model_name} with resource monitoring\\n{'='*50}\")\n",
    "    \n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    model.fit(data, epochs)\n",
    "\n",
    "    final_ram = psutil.virtual_memory().used / (1024 ** 2)\n",
    "    max_gpu_mem = None\n",
    "    if device.type == 'cuda':\n",
    "        max_gpu_mem = torch.cuda.max_memory_allocated() / (1024 ** 2)\n",
    "\n",
    "    duration = time.time() - start_time\n",
    "    test_metrics = test(model, data)\n",
    "\n",
    "    results = {\n",
    "        'test_metrics': test_metrics,\n",
    "        'training_time_sec': duration,\n",
    "        'final_ram_mb': final_ram,\n",
    "        'max_gpu_mem_mb': max_gpu_mem,\n",
    "    }\n",
    "\n",
    "    print(f\"\\n{model_name} finished\")\n",
    "    print(f\"Test Recall: {test_metrics.get('recall', 0):.3f} | \"\n",
    "          f\"F1: {test_metrics.get('f1', 0):.3f} | \"\n",
    "          f\"PR-AUC: {test_metrics.get('pr_auc', 0):.3f}\")\n",
    "    print(f\"Training Time: {duration:.1f} sec\")\n",
    "    if max_gpu_mem:\n",
    "        print(f\"Peak GPU Memory: {max_gpu_mem:.1f} MB\")\n",
    "    print(f\"Final RAM Usage: {final_ram:.1f} MB\")\n",
    "\n",
    "    return test_metrics.get('recall', 0), results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0cf18771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training GraphSAGE with resource monitoring\n",
      "==================================================\n",
      "Epoch   0 | TL: 0.728 | TF1: 0.368 | VL: 0.722 | VF1: 0.446 | VRec: 0.524 | VPR: 0.378\n",
      "Epoch  10 | TL: 0.471 | TF1: 0.690 | VL: 0.586 | VF1: 0.571 | VRec: 0.635 | VPR: 0.616\n",
      "Epoch  20 | TL: 0.362 | TF1: 0.779 | VL: 0.640 | VF1: 0.584 | VRec: 0.635 | VPR: 0.621\n",
      "Epoch  30 | TL: 0.292 | TF1: 0.828 | VL: 0.739 | VF1: 0.555 | VRec: 0.603 | VPR: 0.630\n",
      "Epoch  40 | TL: 0.251 | TF1: 0.825 | VL: 0.951 | VF1: 0.525 | VRec: 0.508 | VPR: 0.614\n",
      "Epoch  50 | TL: 0.214 | TF1: 0.859 | VL: 0.836 | VF1: 0.590 | VRec: 0.651 | VPR: 0.691\n",
      "Epoch  60 | TL: 0.153 | TF1: 0.901 | VL: 1.185 | VF1: 0.585 | VRec: 0.603 | VPR: 0.587\n",
      "Epoch  70 | TL: 0.147 | TF1: 0.904 | VL: 1.203 | VF1: 0.515 | VRec: 0.540 | VPR: 0.600\n",
      "Epoch  80 | TL: 0.110 | TF1: 0.940 | VL: 1.543 | VF1: 0.512 | VRec: 0.492 | VPR: 0.564\n",
      "Epoch  90 | TL: 0.103 | TF1: 0.952 | VL: 1.557 | VF1: 0.525 | VRec: 0.508 | VPR: 0.584\n",
      "Epoch 100 | TL: 0.078 | TF1: 0.955 | VL: 1.777 | VF1: 0.508 | VRec: 0.524 | VPR: 0.516\n",
      "\n",
      "GraphSAGE finished\n",
      "Test Recall: 0.436 | F1: 0.444 | PR-AUC: 0.462\n",
      "Training Time: 1.8 sec\n",
      "Final RAM Usage: 6534.3 MB\n",
      "CPU times: user 8.01 s, sys: 15.2 ms, total: 8.03 s\n",
      "Wall time: 1.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "results = {}\n",
    "\n",
    "# 1. GraphSAGE\n",
    "graphsage = GraphSAGE(data.x.shape[1], dim_h=64, dim_out=2).to(device)\n",
    "acc_sage, _ = train_with_monitoring(graphsage, data, epochs=100, model_name=\"GraphSAGE\")\n",
    "results['GraphSAGE'] = acc_sage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "694ea93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training GCN with resource monitoring\n",
      "==================================================\n",
      "Epoch   0 | TL: 0.769 | TF1: 0.404 | VL: 0.744 | VF1: 0.408 | VRec: 0.683 | VPR: 0.348\n",
      "Epoch  10 | TL: 0.581 | TF1: 0.583 | VL: 0.634 | VF1: 0.553 | VRec: 0.619 | VPR: 0.527\n",
      "Epoch  20 | TL: 0.548 | TF1: 0.634 | VL: 0.616 | VF1: 0.567 | VRec: 0.635 | VPR: 0.562\n",
      "Epoch  30 | TL: 0.557 | TF1: 0.588 | VL: 0.610 | VF1: 0.548 | VRec: 0.635 | VPR: 0.542\n",
      "Epoch  40 | TL: 0.531 | TF1: 0.627 | VL: 0.657 | VF1: 0.521 | VRec: 0.603 | VPR: 0.491\n",
      "Epoch  50 | TL: 0.514 | TF1: 0.625 | VL: 0.661 | VF1: 0.538 | VRec: 0.667 | VPR: 0.519\n",
      "Epoch  60 | TL: 0.510 | TF1: 0.638 | VL: 0.719 | VF1: 0.550 | VRec: 0.571 | VPR: 0.519\n",
      "Epoch  70 | TL: 0.504 | TF1: 0.640 | VL: 0.700 | VF1: 0.561 | VRec: 0.698 | VPR: 0.467\n",
      "Epoch  80 | TL: 0.500 | TF1: 0.630 | VL: 0.682 | VF1: 0.518 | VRec: 0.571 | VPR: 0.503\n",
      "Epoch  90 | TL: 0.483 | TF1: 0.645 | VL: 0.744 | VF1: 0.517 | VRec: 0.619 | VPR: 0.500\n",
      "Epoch 100 | TL: 0.492 | TF1: 0.643 | VL: 0.645 | VF1: 0.562 | VRec: 0.683 | VPR: 0.569\n",
      "\n",
      "GCN finished\n",
      "Test Recall: 0.673 | F1: 0.493 | PR-AUC: 0.477\n",
      "Training Time: 1.9 sec\n",
      "Final RAM Usage: 6530.1 MB\n",
      "CPU times: user 8.72 s, sys: 14.1 ms, total: 8.73 s\n",
      "Wall time: 1.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 2. GCN\n",
    "gcn = GCN(data.x.shape[1], dim_h=64, dim_out=2).to(device)\n",
    "acc_gcn, _ = train_with_monitoring(gcn, data, epochs=100, model_name=\"GCN\")\n",
    "results['GCN'] = acc_gcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f6f720d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training GAT with resource monitoring\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | TL: 0.974 | TF1: 0.298 | VL: 0.871 | VF1: 0.239 | VRec: 0.206 | VPR: 0.368\n",
      "Epoch  10 | TL: 0.676 | TF1: 0.508 | VL: 0.663 | VF1: 0.488 | VRec: 0.667 | VPR: 0.469\n",
      "Epoch  20 | TL: 0.611 | TF1: 0.519 | VL: 0.678 | VF1: 0.500 | VRec: 0.603 | VPR: 0.467\n",
      "Epoch  30 | TL: 0.629 | TF1: 0.533 | VL: 0.631 | VF1: 0.525 | VRec: 0.667 | VPR: 0.466\n",
      "Epoch  40 | TL: 0.611 | TF1: 0.586 | VL: 0.631 | VF1: 0.583 | VRec: 0.778 | VPR: 0.485\n",
      "Epoch  50 | TL: 0.629 | TF1: 0.541 | VL: 0.611 | VF1: 0.595 | VRec: 0.746 | VPR: 0.547\n",
      "Epoch  60 | TL: 0.596 | TF1: 0.540 | VL: 0.629 | VF1: 0.528 | VRec: 0.667 | VPR: 0.506\n",
      "Epoch  70 | TL: 0.585 | TF1: 0.573 | VL: 0.640 | VF1: 0.575 | VRec: 0.698 | VPR: 0.562\n",
      "Epoch  80 | TL: 0.604 | TF1: 0.593 | VL: 0.628 | VF1: 0.553 | VRec: 0.667 | VPR: 0.558\n",
      "Epoch  90 | TL: 0.591 | TF1: 0.571 | VL: 0.662 | VF1: 0.510 | VRec: 0.587 | VPR: 0.464\n",
      "Epoch 100 | TL: 0.619 | TF1: 0.534 | VL: 0.646 | VF1: 0.500 | VRec: 0.603 | VPR: 0.468\n",
      "\n",
      "GAT finished\n",
      "Test Recall: 0.691 | F1: 0.531 | PR-AUC: 0.534\n",
      "Training Time: 3.3 sec\n",
      "Final RAM Usage: 6521.4 MB\n",
      "CPU times: user 16.7 s, sys: 288 ms, total: 17 s\n",
      "Wall time: 3.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 3. GAT\n",
    "gat = GAT(data.x.shape[1], dim_h=32, dim_out=2, heads=4).to(device)\n",
    "acc_gat, _ = train_with_monitoring(gat, data, epochs=100, model_name=\"GAT\")\n",
    "results['GAT'] = acc_gat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef69257",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphsage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
