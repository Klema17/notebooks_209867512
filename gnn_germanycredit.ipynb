{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e41b79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-{torchversion}.html\n",
    "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-{torchversion}.html\n",
    "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "!pip install torch-geometric pandas numpy scikit-learn networkx matplotlib seaborn tqdm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f014812",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/klema/miniconda3/envs/graphsage/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import to_undirected\n",
    "from torch_geometric.nn import SAGEConv, GATv2Conv, GCNConv\n",
    "import psutil\n",
    "\n",
    "try:\n",
    "    import pynvml\n",
    "    pynvml.nvmlInit()\n",
    "    NVML_AVAILABLE = True\n",
    "except:\n",
    "    NVML_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1015290f",
   "metadata": {},
   "source": [
    "Загружаем датасет German Credit.\n",
    "Содержит 1000 клиентов и 20 признаков (7 числовых и 13 категориальных)\n",
    "Целевая переменная: \"good\" (1) или \"bad\" (2) кредитная история."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dceef23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружено 1000 узлов, 48 признаков\n",
      "Train/Val/Test: 600/200/200\n",
      "Рёбер: 7528\n",
      "Распределение классов: Класс 0: 700, Класс 1: 300\n"
     ]
    }
   ],
   "source": [
    "german_credit = fetch_ucirepo(id=144)\n",
    "\n",
    "X = german_credit.data.features\n",
    "y = german_credit.data.targets \n",
    "\n",
    "# Заменяем \"good\" на 0, \"bad\" на 1\n",
    "y = y['class'].values\n",
    "y = np.where(y == 1, 0, 1)\n",
    "\n",
    "# Обработка категориальных признаков. pd.get_dummies автоматически кодирует все категориальных колонки. drop_first=True убирает избыточность.\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Стандартизация числовых признаков\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Строим граф методом k-ближайших соседей. Создаётся разреженная матрица смежности с помощью knn. Рёбра только 0/1, петли исключаются. Граф неориентированный.\n",
    "k = 5\n",
    "adj_matrix = kneighbors_graph(X_scaled, k, mode='connectivity', include_self=False)\n",
    "edge_index = torch.tensor(np.array(adj_matrix.nonzero()), dtype=torch.long)\n",
    "edge_index = to_undirected(edge_index)\n",
    "\n",
    "# train / val / test (60/20/20)\n",
    "num_nodes = X_scaled.shape[0]\n",
    "indices = np.arange(num_nodes)\n",
    "\n",
    "train_idx, temp_idx = train_test_split(indices, test_size=0.4, random_state=42)\n",
    "val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=42)\n",
    "\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "train_mask[train_idx] = True\n",
    "val_mask[val_idx] = True\n",
    "test_mask[test_idx] = True\n",
    "\n",
    "data = Data(\n",
    "    x=torch.tensor(X_scaled, dtype=torch.float),\n",
    "    edge_index=edge_index,\n",
    "    y=torch.tensor(y, dtype=torch.long),\n",
    "    train_mask=train_mask,\n",
    "    val_mask=val_mask,\n",
    "    test_mask=test_mask\n",
    ")\n",
    "\n",
    "print(f\"Загружено {data.x.shape[0]} узлов, {data.x.shape[1]} признаков\")\n",
    "print(f\"Train/Val/Test: {train_mask.sum().item()}/{val_mask.sum().item()}/{test_mask.sum().item()}\")\n",
    "print(f\"Рёбер: {edge_index.shape[1]}\")\n",
    "\n",
    "class_counts = torch.bincount(data.y).tolist()\n",
    "class_dist_str = \", \".join(f\"Класс {i}: {count}\" for i, count in enumerate(class_counts))\n",
    "print(f\"Распределение классов: {class_dist_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83cea4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred_y, y):\n",
    "    return ((pred_y == y).sum() / len(y)).item()\n",
    "\n",
    "def test(model, data):\n",
    "    model.eval()\n",
    "    _, out = model(data.x, data.edge_index)\n",
    "    acc = accuracy(out.argmax(dim=1)[data.test_mask], data.y[data.test_mask])\n",
    "    return acc\n",
    "\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, dim_in, dim_h, dim_out):\n",
    "        super().__init__()\n",
    "        self.sage1 = SAGEConv(dim_in, dim_h)\n",
    "        self.sage2 = SAGEConv(dim_h, dim_out)\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(),\n",
    "                                        lr=0.01,\n",
    "                                        weight_decay=5e-4)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.sage1(x, edge_index)\n",
    "        h = torch.relu(h)\n",
    "        h = F.dropout(h, p=0.5, training=self.training)\n",
    "        h = self.sage2(h, edge_index)\n",
    "        return h, F.log_softmax(h, dim=1)\n",
    "\n",
    "    def fit(self, data, epochs):\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = self.optimizer\n",
    "\n",
    "        self.train()\n",
    "        for epoch in range(epochs+1):\n",
    "            optimizer.zero_grad()\n",
    "            _, out = self(data.x, data.edge_index)\n",
    "            loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "            acc = accuracy(out[data.train_mask].argmax(dim=1),\n",
    "                          data.y[data.train_mask])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
    "            val_acc = accuracy(out[data.val_mask].argmax(dim=1),\n",
    "                              data.y[data.val_mask])\n",
    "\n",
    "            if(epoch % 10 == 0):\n",
    "                print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc:'\n",
    "                      f' {acc*100:>6.2f}% | Val Loss: {val_loss:.2f} | '\n",
    "                      f'Val Acc: {val_acc*100:.2f}%')\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, dim_in, dim_h, dim_out, heads=4):\n",
    "        super().__init__()\n",
    "        self.gat1 = GATv2Conv(dim_in, dim_h, heads=heads, dropout=0.6)\n",
    "        self.gat2 = GATv2Conv(dim_h*heads, dim_out, heads=heads, dropout=0.6)\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(),\n",
    "                                        lr=0.005,\n",
    "                                        weight_decay=5e-4)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = F.dropout(x, p=0.6, training=self.training)\n",
    "        h = self.gat1(h, edge_index)\n",
    "        h = F.elu(h)\n",
    "        h = F.dropout(h, p=0.6, training=self.training)\n",
    "        h = self.gat2(h, edge_index)\n",
    "        return h, F.log_softmax(h, dim=1)\n",
    "\n",
    "    def fit(self, data, epochs):\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = self.optimizer\n",
    "\n",
    "        self.train()\n",
    "        for epoch in range(epochs+1):\n",
    "            optimizer.zero_grad()\n",
    "            _, out = self(data.x, data.edge_index)\n",
    "            loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "            acc = accuracy(out[data.train_mask].argmax(dim=1),\n",
    "                          data.y[data.train_mask])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Validation\n",
    "            val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
    "            val_acc = accuracy(out[data.val_mask].argmax(dim=1),\n",
    "                              data.y[data.val_mask])\n",
    "\n",
    "            if(epoch % 10 == 0):\n",
    "                print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc:'\n",
    "                      f' {acc*100:>6.2f}% | Val Loss: {val_loss:.2f} | '\n",
    "                      f'Val Acc: {val_acc*100:.2f}%')\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, dim_in, dim_h, dim_out):\n",
    "        super().__init__()\n",
    "        self.gcn1 = GCNConv(dim_in, dim_h)\n",
    "        self.gcn2 = GCNConv(dim_h, dim_out)\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(),\n",
    "                                        lr=0.01,\n",
    "                                        weight_decay=5e-4)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = F.dropout(x, p=0.5, training=self.training)\n",
    "        h = self.gcn1(h, edge_index)\n",
    "        h = torch.relu(h)\n",
    "        h = F.dropout(h, p=0.5, training=self.training)\n",
    "        h = self.gcn2(h, edge_index)\n",
    "        return h, F.log_softmax(h, dim=1)\n",
    "\n",
    "    def fit(self, data, epochs):\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = self.optimizer\n",
    "\n",
    "        self.train()\n",
    "        for epoch in range(epochs+1):\n",
    "            optimizer.zero_grad()\n",
    "            _, out = self(data.x, data.edge_index)\n",
    "            loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "            acc = accuracy(out[data.train_mask].argmax(dim=1),\n",
    "                          data.y[data.train_mask])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Validation\n",
    "            val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
    "            val_acc = accuracy(out[data.val_mask].argmax(dim=1),\n",
    "                              data.y[data.val_mask])\n",
    "\n",
    "            if(epoch % 10 == 0):\n",
    "                print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc:'\n",
    "                      f' {acc*100:>6.2f}% | Val Loss: {val_loss:.2f} | '\n",
    "                      f'Val Acc: {val_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f8006aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = data.to(device)\n",
    "\n",
    "def monitor_resources():\n",
    "    stats = {}\n",
    "    # CPU & RAM\n",
    "    stats['ram_mb'] = psutil.virtual_memory().used / (1024 ** 2)\n",
    "    stats['cpu_percent'] = psutil.cpu_percent()\n",
    "\n",
    "    # GPU\n",
    "    if device.type == 'cuda' and NVML_AVAILABLE:\n",
    "        handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "        mem_info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "        util = pynvml.nvmlDeviceGetUtilizationRates(handle)\n",
    "        stats['gpu_mem_mb'] = mem_info.used / (1024 ** 2)\n",
    "        stats['gpu_util'] = util.gpu\n",
    "    else:\n",
    "        stats['gpu_mem_mb'] = None\n",
    "        stats['gpu_util'] = None\n",
    "    return stats\n",
    "\n",
    "def train_with_monitoring(model, data, epochs, model_name):\n",
    "    print(f\"\\n{'='*50}\\nTraining {model_name} with resource monitoring\\n{'='*50}\")\n",
    "    \n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    model.fit(data, epochs)\n",
    "\n",
    "    final_ram = psutil.virtual_memory().used / (1024 ** 2)\n",
    "    max_gpu_mem = None\n",
    "    if device.type == 'cuda':\n",
    "        max_gpu_mem = torch.cuda.max_memory_allocated() / (1024 ** 2)  # MB\n",
    "\n",
    "    duration = time.time() - start_time\n",
    "    test_acc = test(model, data)\n",
    "\n",
    "    results = {\n",
    "        'test_acc': test_acc,\n",
    "        'training_time_sec': duration,\n",
    "        'final_ram_mb': final_ram,\n",
    "        'max_gpu_mem_mb': max_gpu_mem,\n",
    "    }\n",
    "\n",
    "    print(f\"\\n{model_name} finished\")\n",
    "    print(f\"Test Accuracy: {test_acc*100:.2f}%\")\n",
    "    print(f\"Training Time: {duration:.1f} sec\")\n",
    "    if max_gpu_mem:\n",
    "        print(f\"Peak GPU Memory: {max_gpu_mem:.1f} MB\")\n",
    "    print(f\"Final RAM Usage: {final_ram:.1f} MB\")\n",
    "\n",
    "    return test_acc, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cf18771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training GraphSAGE with resource monitoring\n",
      "==================================================\n",
      "Epoch   0 | Train Loss: 0.687 | Train Acc:  59.00% | Val Loss: 0.70 | Val Acc: 55.00%\n",
      "Epoch  10 | Train Loss: 0.439 | Train Acc:  80.00% | Val Loss: 0.56 | Val Acc: 71.00%\n",
      "Epoch  20 | Train Loss: 0.332 | Train Acc:  86.67% | Val Loss: 0.59 | Val Acc: 71.50%\n",
      "Epoch  30 | Train Loss: 0.287 | Train Acc:  86.83% | Val Loss: 0.68 | Val Acc: 72.50%\n",
      "Epoch  40 | Train Loss: 0.188 | Train Acc:  92.83% | Val Loss: 0.75 | Val Acc: 74.50%\n",
      "Epoch  50 | Train Loss: 0.176 | Train Acc:  92.50% | Val Loss: 0.81 | Val Acc: 74.50%\n",
      "Epoch  60 | Train Loss: 0.167 | Train Acc:  92.83% | Val Loss: 1.01 | Val Acc: 71.50%\n",
      "Epoch  70 | Train Loss: 0.131 | Train Acc:  94.67% | Val Loss: 1.08 | Val Acc: 69.50%\n",
      "Epoch  80 | Train Loss: 0.105 | Train Acc:  96.17% | Val Loss: 1.10 | Val Acc: 73.00%\n",
      "Epoch  90 | Train Loss: 0.093 | Train Acc:  96.83% | Val Loss: 1.33 | Val Acc: 72.00%\n",
      "Epoch 100 | Train Loss: 0.077 | Train Acc:  97.67% | Val Loss: 1.07 | Val Acc: 73.50%\n",
      "\n",
      "GraphSAGE finished\n",
      "Test Accuracy: 74.50%\n",
      "Training Time: 0.4 sec\n",
      "Final RAM Usage: 8049.2 MB\n",
      "CPU times: user 2.47 s, sys: 42.2 ms, total: 2.51 s\n",
      "Wall time: 456 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "results = {}\n",
    "\n",
    "# 1. GraphSAGE\n",
    "graphsage = GraphSAGE(data.x.shape[1], dim_h=64, dim_out=2).to(device)\n",
    "acc_sage, _ = train_with_monitoring(graphsage, data, epochs=100, model_name=\"GraphSAGE\")\n",
    "results['GraphSAGE'] = acc_sage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "694ea93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training GCN with resource monitoring\n",
      "==================================================\n",
      "Epoch   0 | Train Loss: 0.837 | Train Acc:  45.17% | Val Loss: 0.80 | Val Acc: 44.00%\n",
      "Epoch  10 | Train Loss: 0.557 | Train Acc:  73.83% | Val Loss: 0.62 | Val Acc: 71.00%\n",
      "Epoch  20 | Train Loss: 0.507 | Train Acc:  74.50% | Val Loss: 0.56 | Val Acc: 72.50%\n",
      "Epoch  30 | Train Loss: 0.490 | Train Acc:  76.50% | Val Loss: 0.57 | Val Acc: 73.50%\n",
      "Epoch  40 | Train Loss: 0.480 | Train Acc:  76.00% | Val Loss: 0.55 | Val Acc: 69.50%\n",
      "Epoch  50 | Train Loss: 0.482 | Train Acc:  76.00% | Val Loss: 0.57 | Val Acc: 73.50%\n",
      "Epoch  60 | Train Loss: 0.472 | Train Acc:  77.67% | Val Loss: 0.57 | Val Acc: 72.50%\n",
      "Epoch  70 | Train Loss: 0.459 | Train Acc:  78.33% | Val Loss: 0.60 | Val Acc: 73.00%\n",
      "Epoch  80 | Train Loss: 0.469 | Train Acc:  78.50% | Val Loss: 0.56 | Val Acc: 74.00%\n",
      "Epoch  90 | Train Loss: 0.461 | Train Acc:  77.50% | Val Loss: 0.59 | Val Acc: 68.50%\n",
      "Epoch 100 | Train Loss: 0.458 | Train Acc:  78.33% | Val Loss: 0.60 | Val Acc: 73.00%\n",
      "\n",
      "GCN finished\n",
      "Test Accuracy: 73.00%\n",
      "Training Time: 0.6 sec\n",
      "Final RAM Usage: 8050.2 MB\n",
      "CPU times: user 3.11 s, sys: 593 ms, total: 3.71 s\n",
      "Wall time: 648 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 2. GCN\n",
    "gcn = GCN(data.x.shape[1], dim_h=64, dim_out=2).to(device)\n",
    "acc_gcn, _ = train_with_monitoring(gcn, data, epochs=100, model_name=\"GCN\")\n",
    "results['GCN'] = acc_gcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f6f720d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training GAT with resource monitoring\n",
      "==================================================\n",
      "Epoch   0 | Train Loss: 4.360 | Train Acc:   5.83% | Val Loss: 4.32 | Val Acc: 6.50%\n",
      "Epoch  10 | Train Loss: 1.166 | Train Acc:  58.83% | Val Loss: 1.19 | Val Acc: 59.50%\n",
      "Epoch  20 | Train Loss: 0.758 | Train Acc:  67.67% | Val Loss: 0.81 | Val Acc: 60.50%\n",
      "Epoch  30 | Train Loss: 0.658 | Train Acc:  69.67% | Val Loss: 0.70 | Val Acc: 64.50%\n",
      "Epoch  40 | Train Loss: 0.646 | Train Acc:  69.83% | Val Loss: 0.64 | Val Acc: 73.00%\n",
      "Epoch  50 | Train Loss: 0.631 | Train Acc:  70.17% | Val Loss: 0.66 | Val Acc: 70.00%\n",
      "Epoch  60 | Train Loss: 0.603 | Train Acc:  69.67% | Val Loss: 0.63 | Val Acc: 69.00%\n",
      "Epoch  70 | Train Loss: 0.614 | Train Acc:  69.67% | Val Loss: 0.63 | Val Acc: 70.00%\n",
      "Epoch  80 | Train Loss: 0.603 | Train Acc:  69.50% | Val Loss: 0.65 | Val Acc: 66.50%\n",
      "Epoch  90 | Train Loss: 0.594 | Train Acc:  68.67% | Val Loss: 0.63 | Val Acc: 70.00%\n",
      "Epoch 100 | Train Loss: 0.572 | Train Acc:  70.50% | Val Loss: 0.63 | Val Acc: 69.00%\n",
      "\n",
      "GAT finished\n",
      "Test Accuracy: 75.50%\n",
      "Training Time: 1.5 sec\n",
      "Final RAM Usage: 8208.5 MB\n",
      "CPU times: user 8.28 s, sys: 1.08 s, total: 9.36 s\n",
      "Wall time: 1.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 3. GAT\n",
    "gat = GAT(data.x.shape[1], dim_h=32, dim_out=2, heads=4).to(device)\n",
    "acc_gat, _ = train_with_monitoring(gat, data, epochs=100, model_name=\"GAT\")\n",
    "results['GAT'] = acc_gat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef69257",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphsage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
